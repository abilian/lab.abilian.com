
- https://github.com/abetlen/llama-cpp-python = Python bindings for llama.cpp
- https://github.com/langchain-ai/langchain = Building applications with LLMs through composability
- https://github.com/advanced-stack/py-llm-core = A pythonic library providing light-weighted interface with LLMs
- https://github.com/dagworks-inc/burr = Build applications that make decisions (chatbots, agents, simulations, etc...). Monitor, persist, and execute on your own infrastructure.

## Notes on LangChain

- https://www.octomind.dev/blog/why-we-no-longer-use-langchain-for-building-our-ai-agents
- https://www.reddit.com/r/LocalLLaMA/comments/1d4p1t6/is_langchain_usable/ "I don’t know you, but when I build an LLM app for a client LangChain is always more of a hassle to get started than just writing the ‘supporting’ code myself."

<!-- Keywords -->
#ai #llm
<!-- /Keywords -->
